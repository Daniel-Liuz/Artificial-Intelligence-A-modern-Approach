# 2.1 智能体和环境

## 核心概念定义

### 智能体(Agent)的定义

- 任何通过**传感器**(sensor)感知环境(environment)并通过**执行器**(actuator)作用于该环境的事物
- 智能体可以是:
    - 人类智能体(传感器:眼耳等器官;执行器:手脚声道等)
    - 机器人智能体(传感器:摄像头红外测距仪;执行器:电动机)
    - 软件智能体(传感输入:文件内容/网络数据包/人工输入;执行:写文件/发数据包/显示信息)
    ![[2-1智能体通过传感器和执行器与环境交互.png]]
    

### 感知(Percept)相关概念

- **感知**: 智能体传感器正在感知的内容
- **感知序列**(percept sequence): 智能体所感知的完整历史
- 智能体的动作选择依赖于:
    - 内置知识
    - 迄今为止观察到的整个感知序列

### 智能体函数与程序

- **智能体函数**(agent function):
    
    - 数学描述:将任意给定的感知序列映射到一个动作
    - 可以用表格形式表示(通常很大或无限)
- **智能体程序**(agent program):
    
    - 智能体函数的具体实现
    - 运行在物理系统中

## 示例:真空吸尘器世界

### 环境设置

- 由方格组成的世界
- 包含机器人真空吸尘器智能体
- 方格状态:脏/干净
- 简单示例:只有方格A和B
![[2-2一个只有2个吸尘器的世界.png]]
### 智能体特征

- 感知能力:
    - 当前所在方格位置
    - 方格是否干净
- 可选操作:
    - 向右移动
    - 向左移动
    - 吸尘
    - 不动
- 简单智能体函数示例:
    - 当前方格脏→吸尘
    - 当前方格干净→移动到另一个方格
![[2-3智能体函数.png]]
# 2.2 良好行为：理性的概念
理性智能体（rational agent）是做正确事情的事物。显然，做正确的事情比做错误的事情要好，但是做正确的事情意味着什么呢？
## 2.2.1 性能度量

### 结果主义方法

- 通过**结果**来评估智能体的行为
- 智能体的动作序列导致环境状态序列的变化
- 使用**性能度量**(performance measure)评估状态序列的理想程度

### 性能度量的设计原则
**根据一个人在环境中真正想要实现的目标，而不是根据一个人认为智能体应该如何表现来设计性能度量**
1. 基于真实目标而非预设行为
    - 反例:以清理灰尘量衡量→智能体可能反复倾倒再清理
    - 正确:奖励保持地板清洁的状态
2. 需要考虑的复杂问题
    - 时间分布:均匀vs波动性表现
    - 资源分配:平均vs不均匀分配
    - 短期vs长期收益的权衡
3. 重要提醒
    - 性能度量需要反映用户真实偏好
    - 要考虑不同用户可能有不同偏好
    - 智能体可能需要学习和适应用户的真实偏好

## 2.2.2 理性

### 理性的四个决定因素

1. 性能度量(定义成功标准)
2. 环境的先验知识
3. 可执行的动作
4. 当前的感知序列

### 理性智能体的定义

对于每个可能的感知序列,理性智能体应该:

- 基于已有感知序列的证据
- 结合先验知识
- **选择能最大化期望性能度量的动作**

### 示例分析:真空吸尘器智能体

需要明确以下条件才能判断理性:

- 性能度量:每个干净方格每时间步得1分
- 环境知识:已知地理信息,未知灰尘分布
- 可用动作:Left、Right、Suck
- 感知能力:位置和灰尘状态

## 2.2.3 全知、学习和自主

### 理性vs全知

- **全知**:能预知行动的实际结果(不现实)
- **理性**:基于已知信息最大化期望性能
- 理性≠完美:不要求事后证明是最优选择

### 信息收集(在第十六章有详细介绍)

- 理性智能体应主动收集信息
- 例如:过马路前观察路况
- 探索未知环境是信息收集的形式

### 学习能力

- 理性智能体应从经验中学习
- 可以修改和增强初始知识
- 适应环境变化

### 自主性

- **自主性**:不过度依赖设计者的先验知识
- 理性智能体应该:
    - 能弥补不完整的先验知识s
    - 纠正错误的先验知识
    - 通过经验逐渐独立于初始知识
- 平衡考虑:
    - 需要一定初始知识启动
    - 最终应通过学习实现自主

# 2.3 环境的本质

## 2.3.1 指定任务环境 (PEAS描述)

任务环境是"问题",理性智能体是其"解决方案"。在设计智能体时,第一步必须完整指定任务环境的PEAS:

### PEAS框架

- **P**erformance measure (性能度量)
- **E**nvironment (环境)
- **A**ctuator (执行器)
- **S**ensor (传感器)

### 详细示例1: 自动驾驶出租车

| 智能体类型     | 性能度量                                                                    | 环境                                                         | 执行器                                                                | 传感器                                                                                   |
| --------- | ----------------------------------------------------------------------- | ---------------------------------------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------------------------- |
| 自动驾驶出租车司机 | • 安全  <br>• 速度快  <br>• 合法  <br>• 舒适旅程  <br>• 最大化利润  <br>• 对其他道路用户的影响最小化 | • 道路  <br>• 其他交通工具  <br>• 警察  <br>• 行人  <br>• 客户  <br>• 天气 | • 转向器  <br>• 加速器  <br>• 制动  <br>• 信号  <br>• 喇叭  <br>• 显示  <br>• 语音 | • 摄像头  <br>• 雷达  <br>• 速度表  <br>• GPS  <br>• 发动机传感器  <br>• 加速度表  <br>• 麦克风  <br>• 触摸屏 |

### 详细示例2: 医疗诊断系统

|类型|性能度量|环境|执行器|传感器|
|---|---|---|---|---|
|医学诊断系统|• 治愈患者  <br>• 降低费用|• 患者  <br>• 医院  <br>• 工作人员|• 问题显示  <br>• 测试显示  <br>• 诊断显示  <br>• 治疗显示|• 触摸屏输入  <br>• 语音输入(用于症状和检验结果)|

### 其他系统的PEAS示例

| 智能体类型    | 性能度量                     | 环境                           | 执行器                                            | 传感器                                            |
| -------- | ------------------------ | ---------------------------- | ---------------------------------------------- | ---------------------------------------------- |
| 卫星图像分析系统 | 正确分类对象和地形                | - 轨道卫星  <br>- 下行链路  <br>- 天气 | 场景分类显示器                                        | 高分辨率数字照相机                                      |
| 零件选取机器人  | 零件在正确箱中的比例               | - 零件输送带  <br>- 箱子            | - 有关节的手臂  <br>- 手                              | - 摄像头  <br>- 触觉传感器  <br>- 关节角度传感器              |
| 提炼厂控制器   | - 纯度  <br>- 产量  <br>- 安全 | - 提炼厂  <br>- 原料  <br>- 操作员   | - 阀门  <br>- 泵  <br>- 加热器  <br>- 搅拌器  <br>- 显示器 | - 温度传感器  <br>- 气压传感器  <br>- 流量传感器  <br>- 化学传感器 |
| 交互英语教师   | 学生的考试分数                  | - 一组学生  <br>- 考试机构           | - 练习显示  <br>- 反馈显示  <br>- 发言显示                 | - 键盘输入  <br>- 语音                               |

## 2.3.2 任务环境的属性

### 1. 可观测性 (Observability)

#### 完全可观测环境

- 传感器可获取环境完整状态
- 决策所需信息完全可得
- 示例: 国际象棋棋盘状态

#### 部分可观测环境

- 传感器信息不完整
- 可能存在传感器噪声
- 示例: 自动驾驶中的交通状况

#### 不可观测环境

- 无法直接获取环境信息
- 需要维护内部状态估计
- 示例: 纸牌游戏中其他玩家的手牌

### 2. 智能体数量 (Agency)

#### 单智能体环境

- 环境中只有一个决策实体
- 无需考虑其他智能体的影响
- 示例: 独立解决数独游戏

#### 多智能体环境

- **竞争性环境**
    - 智能体目标相互冲突
    （A智能体想让B的性能度量最小化，让自己的性能度量最大化）
    - 示例: 棋类游戏
- **合作性环境**
    - 智能体目标一致或互补
    - 示例: 交通中的避让协调

### 3. 确定性 (Determinism)

#### 确定性环境

- 下一状态完全由当前状态和动作决定
- 无不确定性因素
- 示例: 简单的机械系统

#### 非确定性环境

- 相同动作可能导致不同结果
- 包含不可预测因素
- 示例: 真实交通环境

#### 随机环境

- 状态转换具有明确的概率分布
- 可以量化不确定性
- 示例: 赌博游戏

### 4. 回合性 (Episodic vs Sequential)

#### 回合式环境

- 任务可分为独立的回合
- 当前决策不影响未来回合
- 示例: 图像分类任务

#### 序贯式环境

- 当前决策影响未来状态
- 需要考虑长期影响
- 示例: 国际象棋、驾驶

### 5. 动态性 (Dynamics)

#### 静态环境

- 环境在决策过程中保持不变
- 无时间压力
- 示例: 填字游戏

#### 动态环境

- 环境持续变化
- 需要实时响应
- 示例: 实时控制系统

#### 半动态环境

- 环境本身不变
- 性能评分随时间变化
- 示例: 限时象棋

### 6. 离散/连续 (Discrete/Continuous)

#### 离散环境

- 有限状态、动作和感知
- 清晰的状态划分
- 示例: 棋类游戏

#### 连续环境

- 状态空间连续
- 动作和感知是连续值
- 示例: 机器人控制

### 7. 已知/未知 (Known/Unknown)

#### 已知环境

- 环境规则完全已知
- 动作结果可预测
- 示例: 标准棋类游戏

#### 未知环境

- 环境规则需要学习
- 需要探索和适应
- 示例: 新的控制任务

### 任务环境的例子及其特征

|任务环境|可观测|智能体|确定性|回合式|静态|离散|
|---|---|---|---|---|---|---|
|填字游戏|完全|单|确定性|序贯|静态|离散|
|限时国际象棋|完全|多|确定性|序贯|半动态|离散|
|扑克|部分|多|非确定性|序贯|静态|离散|
|西洋双陆棋|完全|多|非确定性|序贯|静态|离散|
|驾驶出租车|部分|多|非确定性|序贯|动态|连续|
|医疗诊断|部分|单|非确定性|序贯|动态|连续|
|图片分析|完全|单|确定性|回合式|半动态|连续|
|零件选取机器人|部分|单|非确定性|回合式|动态|连续|
|提炼厂控制器|部分|单|非确定性|序贯|动态|连续|
|交互英语教师|部分|多|非确定性|序贯|动态|离散|

# 2.4 智能体的结构
人工智能的工作是设计一个智能体程序（agent program）实现智能体函数，即从感知到动作的映射。假设该程序将运行在某种具有物理传感器和执行器的计算设备上，我们称之为智能体架构（agent architecture）：

**智能体 = 架构 + 程序**

## 2.4.1 智能体程序

本节讨论了智能体程序的基本框架和关键思想。

---

### 1. 智能体程序与智能体函数

- **输入与输出**  
    智能体程序接收**当前感知（percept）作为输入，并返回动作给执行器。
    - **注意**：智能体程序只使用当前感知，而智能体函数可能依赖整个感知历史。
    - 在环境中没有其他可用信息的情况下，智能体程序只能利用当前感知。如果智能体动作需要参考历史，则必须在内部保存感知序列。

---

### 2. 表驱动智能体程序

#### 2.1 伪代码描述
```pseudo
function Table-Driven-Agent(percept) returns 一个动作
    persistent: percepts，初始为空的序列
                table，以感知序列为索引的动作表，初始为完全确定
    将 percept 添加到 percepts 的末尾
    action ← Lookup(percepts, table)
    return action
```
- 每次新的感知到来时，程序会调用 `Table-Driven-Agent`，并返回一个对应的动作。
- 内部维护的 `percepts` 存储了完整的感知历史，而 `table` 则映射每个可能的感知序列到一个具体动作。
#### 2.2 表驱动方法的问题

书中讨论了表驱动方法在实际应用中的严重局限性：

- **存储空间问题**  
    假设感知集为 P，智能体生存期为 T（即总共接收 T 个感知），则动作表需要包含 $∣P∣^T$条记录。例如：
    - **自动驾驶出租车**：单个摄像头每秒产生 70 MB 数据（30 帧、每帧 1080×720 像素，每像素 24 位颜色信息），驾驶 1 小时后生成的数据量将导致表中包含超过 $10^{13}$ 条记录。
    - 即使是国际象棋这样相对简单的场景，其查找表也至少需要 $10^{150}$ 条记录。
    - 相比之下，可观测宇宙中的原子总数少于 $10^{80}$，显然不可能存储如此巨量的数据。
## 2.4.2 简单反射型智能体
![[2-9简单反射性智能体.png]]
### 概述

- **基本机制**：直接依据当前的感知来做出决策，不考虑历史信息。
- **核心思想**：使用**条件—动作规则**，类似于查表法，只要满足某个条件就触发对应动作。

### 工作流程

1. **感知阶段**：智能体通过传感器获取当前环境信息。
2. **规则匹配**：将感知输入与预设规则进行匹配。
3. **执行动作**：若发现规则满足条件，则立即执行对应动作。

### 优缺点分析

- **优点**：
    - 结构简单，实现容易。
    - 响应速度快，适用于实时反应要求高的场景。
- **缺点**：
    - 不能处理**部分可观测环境**：当感知信息不完全或存在噪声时，容易出错。
    - 无法记忆或学习：每次决策都只依赖于当前感知，缺乏对过去经验的利用。

---

## 2.4.3 基于模型的反射型智能体
![[2-11基于模型的智能体.png]]
### 概述

- **核心思想**：维护一个内部模型，用以表示环境状态，从而对感知信息进行解释和补全。
- **内部状态**：不仅仅依赖当前感知，而是通过历史数据估计出当前真实的环境状态。

### 关键组件

1. **传感器模型**：
    - 描述感知设备如何把真实世界映射为智能体的输入。
    - 包括误差校正、滤波等处理，使得感知结果更稳定。
2. **状态转移模型**：
    - 表示环境如何随时间变化。
    - 模型可以是确定性或概率性，用来预测下一时刻状态。

### 工作流程

1. **更新内部状态**：结合上一次的状态和当前的感知，利用状态转移模型更新内部状态。
2. **决策阶段**：根据更新后的状态和预设规则做出决策。
3. **执行动作**：动作反馈可能改变环境，从而影响下一轮状态更新。

### 优缺点分析

- **优点**：
    - 能够处理部分可观测环境，提高决策准确性。
    - 通过模型的维护，可以在一定程度上对感知噪声进行补偿。
- **缺点**：
    - 模型构建较复杂，需要对环境进行较精确的建模。
    - 对于环境变化较快或模型不准确的情况，可能会导致误判。

---

## 2.4.4 基于目标的智能体
![[2-13基于模型、基于目标的智能体.png]]
### 概述

- **目标驱动**：在基于模型的基础上，引入了明确的目标描述。
- **规划与搜索**：智能体不仅要根据当前状态做出决策，更要计划未来行动以达到预定目标。

### 工作流程

1. **目标检测**：评估当前状态与目标状态的差距。
2. **规划阶段**：
    - 使用搜索算法（如A*、Dijkstra等）规划出一系列动作，逐步缩小与目标状态的差距。
    - 考虑多种可能性，选择一条最优或近似最优路径。
3. **执行与反馈**：
    - 按计划执行动作，同时监控实际效果，若出现偏差则重新规划。

### 优缺点分析

- **优点**：
    - 能够适应多目标情境和复杂任务。
    - 灵活性高，通过规划可应对环境中的不确定性。
- **缺点**：
    - 规划和搜索可能带来较高的计算复杂度。
    - 目标描述不当或环境模型不准确时，规划效果可能大打折扣。

---

## 2.4.5 基于效用的智能体
![[2-14基于效用的智能体.png]]
### 概述

- **效用函数**：不仅考虑是否能达到目标，还评估不同状态的“好坏”，以更精细地量化决策效果。
- **决策原则**：选择期望效用最大的动作，即在当前状态下采取使整体效用最大化的策略。

### 工作流程

1. **状态评估**：
    - 每个可能的状态根据效用函数获得一个数值，表示其“好坏”。
2. **动作选择**：
    - 对每个动作进行预期效用计算，选择那个期望效用最高的动作。
3. **动态反馈**：
    - 根据执行结果调整效用函数的参数，实现持续改进。

### 优缺点分析

- **优点**：
    - 能够平衡多目标冲突，更精细地反映实际需求。
    - 在面对不确定环境时，通过概率加权得到较为稳健的决策。
- **缺点**：
    - 效用函数的设计与调试较为困难，需要准确量化不同状态的价值。
    - 计算过程可能较复杂，尤其是在状态空间大或效用函数非线性时。

---

## 2.4.6 学习型智能体(在第十九章会更深入)
本节讨论了学习型智能体的核心思想及其组成部分，并说明了为什么采用学习机制是构建先进人工智能系统的关键。相对于传统的静态智能体，学习型智能体不仅能够适应未知环境，还能通过不断自我改进，从而超越最初编程时所设定的能力。
### 1. 引言与动机

- **早期设想与局限**  
    图灵在 1950 年的论文中提出，直接手动编程智能机器可能需要耗费巨大的人力工作。由此，他设想“学习型机器”作为更快捷的替代方案。
    
    - 学习型智能体允许系统通过与环境交互获得反馈，然后根据这些反馈调整自身行为，从而在面对初始未知或部分未知环境时仍能表现出良好的适应性。
- **超越初始知识**  
    通过学习，智能体可以在运行过程中积累经验，不仅仅局限于设计者预先编写的规则或模型。
    
    - 这种机制使得智能体在现实应用中能不断改进其性能，提升决策的准确性和鲁棒性。

---

### 2. 学习型智能体的基本架构

学习型智能体可分为四个主要的概念组件，每个组件负责不同的功能，相互协作实现系统整体性能的不断提升。下图（图 2-15）展示了通用的学习型智能体框架，其中“性能元素”代表传统智能体程序，“学习元素”负责对性能元素进行改进。
![[2-15学习型智能体.png]]
#### 2.1 主要组件

1. **性能元素 (Performance Element)**
    
    - 负责接收感知并直接选择动作。
    - 实际上，性能元素就是传统意义上的智能体程序，它体现了当前已知的知识和行为策略。
2. **学习元素 (Learning Element)**
    
    - 负责基于反馈信息修改和改进性能元素。
    - 设计学习元素时，首先要明确性能元素的结构，然后构造相应的学习机制，使其能够逐步提高决策水平。
3. **评估者 (Critic)**
    
    - 提供外部反馈，评估智能体的表现是否符合预期。
    - 评估者独立于智能体，其性能标准（如奖励或惩罚）通常来源于外部环境或人类反馈。
    - 例如，在国际象棋程序中，评估者负责判断一次走棋是否带来有利局面；在自动驾驶中，评估者可能通过乘客的反馈或车辆行为安全性进行评价。
4. **问题生成器 (Problem Generator)**
    
    - 负责建议新的、探索性的动作，这些动作可能在短期内表现欠佳，但有助于长期发现更优的策略。
    - 问题生成器的作用类似于科学实验，通过“试错”探索未知领域，从而为学习元素提供宝贵的新信息。

---

### 3. 学习型智能体的工作流程

学习型智能体在运行时的基本流程可以概括为以下几个步骤：

1. **感知与执行**
    
    - 性能元素根据当前感知决定执行某个动作。
2. **反馈收集**
    
    - 环境或外部用户提供反馈（奖励、惩罚或其他性能指标），这些反馈由评估者捕获。
3. **学习与改进**
    
    - 学习元素接收评估者反馈，根据实际效果对性能元素的内部模型、动作选择策略或效用函数等进行调整和优化。
4. **探索与试验**
    
    - 问题生成器建议尝试新的动作，即使这些动作在短期内可能不是最优的。通过这种探索，智能体可以发现新的可能性，更新和改进其内部知识结构。
5. **循环迭代**
    
    - 在不断的交互和学习过程中，智能体逐步改进自身性能，形成闭环反馈机制，从而在长期运行中不断优化决策效果。

---

### 4. 学习型智能体的关键意义

- **适应性与鲁棒性**  
    学习机制使得智能体在面对环境变化或初始知识不足时，能够自我调节、逐步适应复杂环境。例如，自动驾驶出租车可以在湿滑路面上通过反复试验逐步掌握刹车时的减速情况，从而降低事故风险。
    
- **外部性能标准的重要性**  
    感知信息本身并不包含行为成功与否的明确指示。性能标准（通过评估者传递）将部分感知转化为奖励或惩罚信号，为智能体提供明确的改进方向。
    
    - 例如，出租车因乘客不适而失去小费，反馈信息就会促使系统修改其驾驶策略，避免暴力操作或其他不合适的行为。
- **探索与利用的平衡**  
    问题生成器在系统中的存在提醒我们，智能体如果仅仅依赖当前已知的最佳动作，会错失进一步探索更优策略的机会。
    
    - 这种平衡正是许多学习算法（如强化学习）中重要的探索-利用问题所要解决的核心挑战。

---

### 5. 实际应用中的案例与启示

- **自动驾驶系统**  
    自动驾驶车辆通过不断实验（例如，在不同路况下的刹车尝试），学习并调整其驾驶策略，提高安全性和乘坐体验。
    
- **游戏智能体**  
    在国际象棋等对抗性游戏中，智能体通过不断对弈、评估走棋效果，逐渐优化决策模型，甚至超越人类大师。
    
- **机器人控制**  
    机器人在执行任务时，通过环境反馈不断修正动作参数，使得任务完成更加高效和精确。
    

这些实例表明，学习型智能体在多种场景下均能通过不断改进其内部组件，实现比最初设计时更为出色的表现。

---

## 2.4.7 智能体程序的组件如何工作
![[2-16组件工作方式.png]]
### 状态表示方式

有效的状态表示是构建高性能智能体的基础，常用的表示方法包括：

1. **原子表示**：
    - 状态作为不可分割的整体表示。
    - 优点在于简单明了；缺点在于缺乏内部结构的信息。
2. **因子化表示**：
    - 状态由多个属性或变量构成，每个属性代表状态的一个方面（例如：燃油量、车速、GPS位置）。
    - 这种方法提高了表示的细粒度，便于局部调整和计算。
3. **结构化表示**：
    - 状态由对象、属性以及对象之间的关系构成。
    - 优点在于能捕捉更复杂的情境，便于高级推理；缺点是推理计算量较大，需要更复杂的模型支持。

### 局部表示与分布式表示

- **局部表示**：
    - 每个概念或状态信息存储在单一位置，便于直接访问。
    - 缺点是当信息冗余或部分损坏时，整个系统易受影响。
- **分布式表示**：
    - 概念的信息分布在多个存储单元中，具有更好的鲁棒性。
    - 在处理噪声和部分丢失数据时更稳定，但可能需要更多计算资源来整合信息。

### 实际应用中的考虑

- **表达能力**：
    - 更高级的状态表示（如结构化表示）能够捕捉环境中的复杂关系，但同时要求更复杂的推理机制。
- **计算开销**：
    - 状态表示越详细，计算和存储的需求也越高。因此在设计智能体时需要权衡表示的精细程度和实际应用的资源限制。
## 小结

本章是人工智能的旋风之旅，在这个过程中我们认为人工智能是智能体设计的科学。本章要回顾的要点如下。

- 智能体是在环境中感知和行动的事物。智能体的智能体函数指定智能体在响应任意感知序列时所采取的动作。
- 性能度量评估智能体在环境中的行为。给定到目前为止所看到的感知序列，理性智能体的动作是为了最大化性能度量的期望值。
- 任务环境规范包括性能度量、外部环境、执行器和传感器。在设计智能体时，第一步必须始终是尽可能完整地指定任务环境。
- 任务环境在几个重要维度上有所不同。它们可以是完全可观测的或部分可观测的、单智能体的或多智能体的、确定性的或非确定性的、回合式的或序贯的、静态的或动态的、离散的或连续的、已知的或未知的。
- 在性能度量未知或难以正确指定的情况下，智能体优化错误目标的风险很大。在这种情况下，智能体设计应该反映真实目标的不确定性。
- 智能体程序实现智能体函数。存在各种基本的智能体编程，反映了决策过程中明确使用的信息类型。这些设计在效率、紧凑性和灵活性方面各不相同。智能体程序的适当设计取决于环境的性质。
- 简单反射型智能体直接响应感知，而基于模型的反射型智能体保持内部状态以跟踪当前感知中不明晰的世界状态。基于目标的智能体采取行动来实现目标，而基于效用的智能体试图最大化自己期望的“快乐”。
- 所有智能体都可以通过学习提升性能。
